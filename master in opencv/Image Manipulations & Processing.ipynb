{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'wrapAffine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-037ea197d999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# divide by to rotate image arount its center\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrotation_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRotationMatrix2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrotated_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrotation_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rotated Image:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrotated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'wrapAffine'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/aman.jpg')\n",
    "height,width=image.shape[:2]\n",
    "# divide by to rotate image arount its center\n",
    "rotation_matrix=cv2.getRotationMatrix2D((width/2,height/2),90,1)\n",
    "rotated_image=cv2.wrapAffine(image,rotation_matrix,(width,height))\n",
    "cv2.imshow(\"Rotated Image:\",rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/aman.jpg')\n",
    "rotated_image=cv2.transpose(image)\n",
    "cv2.imshow(\"Rotated Image:\",rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and re-sizing and interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread('/home/mramanymous/Pictures/aman.jpg')\n",
    "\n",
    "image_selected=cv2.resize(image,None,fx=0.75,fy=0.75)\n",
    "cv2.imshow(\"Rotated Image:\",image_selected)\n",
    "cv2.waitKey()\n",
    "\n",
    "# double the size of the image\n",
    "# image_scaled=cv2.resize(image,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n",
    "# cv2.imshow(\"Scaling - Cubic Interpolation:\",image_scaled)\n",
    "# cv2.waitKey()gs exa\n",
    "# skew the re-sizing by the settinct dimension\n",
    "image_scaled=cv2.resize(image,(900,400),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"Scaling-Skewed size:\",image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/aman.jpg')\n",
    "\n",
    "smaller=cv2.pyrDown(image)\n",
    "larger=cv2.pyrUp(smaller)\n",
    "cv2.imshow(\"Original\",smaller)\n",
    "cv2.imshow(\"Smaller\",smaller)\n",
    "cv2.imshow(\"larger\",larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-684d85f770f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# cv2.imshow(\"Original image\",image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cropped image\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "# cropping the image\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/aman.jpg')\n",
    "height,width=image.shape[:2]\n",
    "start_row,start_col=int(height*.75),int(width*.75)\n",
    "end_row,end_col=int(height*.75),int(width*.75)\n",
    "\n",
    "cropped=image[start_row:end_row,start_col:end_col]\n",
    "# cv2.imshow(\"Original image\",image)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imshow(\"Cropped image\",cropped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arithmetic operations\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/aman.jpg')\n",
    "M=np.ones(image.shape,dtype=\"uint8\")*75\n",
    "added=cv2.add(image,M)\n",
    "cv2.imshow(\"added\",added)\n",
    "subtracted=cv2.subtract(image,M)\n",
    "cv2.imshow(\"subtracted\",subtracted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()\n",
    "# jis error show aunko phir bi dobhara run karna ha maybe compiler fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise and masking\n",
    "import cv2\n",
    "import numpy as np\n",
    "square=np.zeros((300,300),np.uint8)\n",
    "cv2.rectangle(square,(50,50),(250,250),255,-2)\n",
    "cv2.imshow(\"square\",square)\n",
    "cv2.waitKey(0)\n",
    "ellipse=np.zeros((300,300),np.uint8)\n",
    "cv2.ellipse(ellipse,(150,150),(150,150),30,0,180,225,-1)\n",
    "cv2.imshow(\"ellipse\",ellipse)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "square=np.zeros((300,300),np.uint8)\n",
    "cv2.rectangle(square,(50,50),(250,250),255,-2)\n",
    "cv2.imshow(\"square\",square)\n",
    "cv2.waitKey(0)\n",
    "ellipse=np.zeros((300,300),np.uint8)\n",
    "cv2.ellipse(ellipse,(150,150),(150,150),30,0,180,225,-1)\n",
    "cv2.imshow(\"ellipse\",ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "And=cv2.bitwise_and(square,ellipse)\n",
    "cv2.imshow(\"AND\",And)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutions and blurring\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/tiger.jpeg')\n",
    "# cv2.imshow(\"original image\",image)\n",
    "# cv2.waitKey(0)\n",
    "# creating 3x3 kernel\n",
    "# kernel_3x3=np.ones((3,3),np.float32)/9\n",
    "# cv2.filter2D to convive the lernel with an image\n",
    "# blurred=cv2.filter2D(image,-1,kernel_3x3)\n",
    "# cv2.imshow(\"3x3 kernel blurring\",blurred)\n",
    "# cv2.waitKey(0)\n",
    "# creating 7x7 kernel\n",
    "kernel_7x7=np.ones((7,7),np.float32)/49\n",
    "blurred=cv2.filter2D(image,-1,kernel_7x7)\n",
    "cv2.imshow(\"7x7 kernel blurring\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/tiger.jpeg')\n",
    "# blur=cv2.blur(image,(3,3))\n",
    "# cv2.imshow(\"averaging\",blur)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# gaussian=cv2.GaussianBlur(image,(7,7),0)\n",
    "# cv2.imshow(\"Gaussian ABlur\",gaussian)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# median=cv2.medianBlur(image,5)\n",
    "# cv2.imshow(\"median ABlur\",median)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "bilateral=cv2.bilateralFilter(image,9,75,75)\n",
    "cv2.imshow(\"bilateral Blur\",bilateral)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/tiger.jpeg')\n",
    "cv2.imshow(\"original\",image)\n",
    "kernel_sharping=np.array([[-1,-1,-1],\n",
    "                         [-1,9,-1],\n",
    "                         [-1,-1,-1]])\n",
    "sharpened=cv2.filter2D(image,-1,kernel_sharping)\n",
    "cv2.imshow(\"image sharping\",sharpened)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgproc/src/thresh.cpp:1647: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'adaptiveThreshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2bfec0c4b932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# using adaptive Threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mADAPTIVE_THRESH_MEAN_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adaptive Mean Thresholding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgproc/src/thresh.cpp:1647: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'adaptiveThreshold'\n"
     ]
    }
   ],
   "source": [
    "# Thersholding,Binarization & Adaptive Thersholding\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/tiger.jpeg')\n",
    "\n",
    "# cv2.imshow('original',image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# values below 127 goes to 0 (black everything above goes to 255(white))\n",
    "# ret,thresh1=cv2.threshold(image,127,225,cv2.THRESH_BINARY)\n",
    "# cv2.imshow(\"Threshold Binary:\",thresh1)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# a practice to blur images as it removes noise\n",
    "image=cv2.GaussianBlur(image,(3,3),0)\n",
    "\n",
    "# using adaptive Threshold\n",
    "thresh=cv2.adaptiveThreshold(image,225,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,3,5)\n",
    "cv2.imshow(\"Adaptive Mean Thresholding\",thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "_,th2=cv2.threshold(image,0,225,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsus thersholding\",thresh)\n",
    "cv2.waitKey(0)\n",
    "# otusus threshold after gaussian filtering\n",
    "blur=cv2.GaussianBlur(image,(5,5),0)\n",
    "_,th3=cv2.threshold(image,0,225,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsus thersholding\",thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'MorphologyEx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-081d9de1eb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mclosing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMorphologyEx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMORPH_CLOSE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'closing'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'MorphologyEx'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/text.png')\n",
    "# cv2.imshow('original',image)\n",
    "# cv2.waitKey(0)\n",
    "# define kernel size\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "# now we erode\n",
    "# erosion=cv2.erode(image,kernel,iterations=1)\n",
    "# cv2.imshow('erosion',erosion)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# dilation=cv2.dilate(image,kernel,iterations=1)\n",
    "# cv2.imshow('dilation',dilation)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# opening=cv2.morphologyEx(image,cv2.MORPH_OPEN,kernel)\n",
    "# cv2.imshow('opening',opening)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "closing=cv2.morphologyEx(image,MORPH_CLOSE,kernel)\n",
    "cv2.imshow('closing',closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection and image Gradiants\n",
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/tiger.jpeg')\n",
    "\n",
    "# height,width=image.shape\n",
    "# # extract scobal edges\n",
    "# sobel_x=cv2.Sobel(image,cv2.CV_64F,0,1,k_size=5)\n",
    "# sobel_y=cv2.Sobel(image,cv2.CV_64F,1,0,k_size=5)\n",
    "# cv2.imshow('original',image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imshow('sobel_x',sobel_x)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imshow('sobel_y',sobel_y)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# sobel_OR=cv2.bitwise_or(sobel_x,sobel_y)\n",
    "# cv2.imshow('sobel_OR',sobel_OR)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# laplacian=cv2.Laplacian(image,cv2.CV_64F)\n",
    "# cv2.imshow('laplacian',laplacian)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "canny=cv2.Canny(image,20,170)\n",
    "cv2.imshow('canny',canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'fillpoly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3af052301e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlane_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcanny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlane_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3af052301e02>\u001b[0m in \u001b[0;36mregion_of_interest\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     14\u001b[0m     ])\n\u001b[1;32m     15\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillpoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolygons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'fillpoly'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Canny(image):\n",
    "    gray = cv2.cvtColor(lane_image,cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    canny = cv2.Canny(blur,50,150)\n",
    "    return canny\n",
    "\n",
    "def region_of_interest(image):\n",
    "    height = image.shape[0]\n",
    "    polygons = np.array([\n",
    "    [(200,height),(1100,height),(550,250)]\n",
    "    ])\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.fillpoly(mask,polygons,255)\n",
    "    return mask\n",
    "\n",
    "\n",
    "image = cv2.imread('/home/mramanymous/Pictures/tiger.jpeg')\n",
    "lane_image = np.copy(image)\n",
    "canny = Canny(lane_image)\n",
    "cv2.imshow('result',region_of_interest(canny))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'wrapPerspective'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4ed2d85482f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpoints_B\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m594\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m594\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPerspectiveTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoints_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mwrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m594\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wrapPerspective'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwraped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'wrapPerspective'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('/home/mramanymous/Pictures/paper.jpeg')\n",
    "# cv2.imshow('original',image)\n",
    "# cv2.waitKey(0)\n",
    "# coordinates of 4 corners in image\n",
    "points_A=np.float32([[320,15],[700,215],[85,610],[420,780]])\n",
    "# our desired output in A4 size paper\n",
    "points_B=np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "M=cv2.getPerspectiveTransform(points_A,points_B)\n",
    "wrapped=cv2.wrapPerspective(image,M,(420,594))\n",
    "cv2.imshow('wrapPerspective',wraped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# live sketch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# sketch generating function\n",
    "def sketch(image):\n",
    "#     convert image into gray scale\n",
    "    img_gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#     clean up the gaussian blur\n",
    "    img_gray_blur=cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "#     EXTRACT NODES\n",
    "    canny_edges=cv2.Canny(img_gray_blur,10,70)\n",
    "#     invert binorize image\n",
    "    ret,mask=cv2.threshold(canny_edges,70,225,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow(\"live sketching through webcamp\",sketch(frame))\n",
    "    if cv2.waitKey(1)==9:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
